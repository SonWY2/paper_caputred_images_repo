arixv: https://arxiv.org/abs/2306.04751
ar5iv: https://ar5iv.labs.arxiv.org/html/2306.04751
github: https://github.com/allenai/open-instruct
submit date: 2023-06-07

[요약]
- Instruction-Tuning이 모델 성능을 향상시키는 것은 명확하나, 단일 또는 조합 데이터셋으로 모든 평가에서 동시에 최고 성능 달성은 어려움.
- 벤치마크 기반 평가로 측정한 모델 기능 차이는 인간 선호도를 정확히 반영하지 못함.
- 65B 와 다양한 데이터셋을 조합하여 fine tuning해도 ChatGPT를 능가하지 못함.
  - 실험결과 가장 우수한 모델은 ChatGPT의 83% GPT-4의 68% 수준
- 다양한 Instruction tuning 데이터로 모델을 학습실험했을 때 가장 중요한 것은 기본 모델의 성능이었음.
  - 더 많은 토큰과 더 오랜 시간 학습된 베이스 모델은 튜닝 후 일관되게 더 높은 성능 발휘
- 특정 도메인 및 기능을 대상으로 하는 데이터셋은 해당 측면에서 모델 성능을 개선하는데 매우 효과적
- 모델 기반 선호도 평가는 모델에 의해 생성된 토큰 수와 밀접한 상관관계가 있음. 즉, 모델 기능의 실제 차이를 넘어선 편향성 존재.
- 정제된 데이터 구성 중요. (사람이 작성한 데이터를 통한 성능 이득 낮음. 예: dolly)

[실험 구성]
- 모델과 데이터셋의 pair-wise한 학습 및 비교 수행
- 모델
  - 7B~65B LLaMa 모델을 활용하여 실험 진행
  - 모델별 비교를 위해 OPT, Pythia 추가 실험
- 데이터 셋
  (표1)
  - 기존 NLP 데이터 세트: SuperNI, Flan V2 등
  - Instruction Tuning 목적으로 사람이 처음부터 작성: Dolly, Open Assistant 1
  - 모델에 의해 생성된 데이터: Self-Instruct, Unnatural Instructions, Alpaca, Baize, GPT4-Alpaca)
  - 사용자 공유 프롬프트: ShareGPT
  - 특정 기술을 위해 만들어진 데이터: codealpaca, CoT

[평가과정]
1) Facets 평가: 특정 벤치마크를 통한 츠정 수행(MMLU, Big-Bench-Hard, TyDiQA 등)
2) 모델 평가 by GPT-4: Davinci-003 모델이 생성한 결과와 학습된 모델의 출력 결과를 쌍별 비교 수행
3) 인간 선호도 평가: 생성 결과의 수용 가능성 / 쌍별 선호도 분석 두 가지 방법으로 측정


[결과]
(표3)
- 각 데이터셋을 학습한 모델의 성능 변화표.
- CodexEval = HumanEval
- 신기하게 일반 Alpaca 질문을 GPT-4로 생성하여 만든 데이터셋을 학습한 모델이 코드 생성을 위한 데이터셋인 code-alpaca를 학습한 것보다 점수가 높음.
1)벤치마크 측정결과"
  (table 5)https://github.com/SonWY2/paper_caputred_images_repo/assets/36894403/4d55a14b-d601-418c-9708-c39120955ef9
  - Instruction tuning은 모든 규모의 모델에 큰 이점 제공
  - 모든 작업에 대해 최적의 성능 발휘하는 데이터 세트 존재하지 않음.
  - 데이터 세트를 결합하면 전반적인 성능이 우수해짐. 그러나, 단일 작업에서 가장 적합하진 않음.
  - 베이스 모델의 성능이 매우 중요.
  (table 2)
2)모델 기반 평가
  - 기존 NLP 데이터셋이 혼합된 데이터로 학습된 모델은 성능이 좋지 않았음
  - 길고 다양한 생성을 장려하는 ShareGPT와 같은 데이터가 성능이 좋음.
  - 이 평가를 분석해 보았을 때, 생성 토큰 수와 강한 상관관계 발견
  - GPT-4의 평가가 단순히 토큰 수만을 계산하는 것은 아니겠지만, 모델 선호도가 반드시 기능과 일치한다는 것을 보장할 수 없음.
3)인간 평가
  - 기존 벤치마크 평가와 대체로 상관관계 있음
    figure 4
  - 정제된 데이터세트를 사용하면 성능이 크게 향상되며, 사람이 직접 작성한 데이터 세트는 이에 비해 부족함. (Dolly와 같은 데이터 사용시 조심해야함)

